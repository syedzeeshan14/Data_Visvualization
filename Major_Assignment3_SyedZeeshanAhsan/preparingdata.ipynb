{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T01:58:21.042946Z",
     "start_time": "2025-11-11T01:58:19.486403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "import re\n",
    "from collections import Counter"
   ],
   "id": "a4522d354632e211",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T01:58:38.298069Z",
     "start_time": "2025-11-11T01:58:38.258336Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('data_scopus.csv')",
   "id": "183dd7a6c04af885",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T01:58:47.397726Z",
     "start_time": "2025-11-11T01:58:47.366915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- 2. Build affiliation mapping ----------\n",
    "affiliation_map = {}\n",
    "for aff_text in df['Authors with affiliations'].dropna():\n",
    "    parts = [a.strip() for a in aff_text.split(';') if a.strip()]\n",
    "    for part in parts:\n",
    "        match = re.match(r\"([^,]+),\\s*(.*)\", part)\n",
    "        if match:\n",
    "            name, aff = match.groups()\n",
    "            name = re.sub(r'[\\s]+$', '', name.strip())\n",
    "            affiliation_map[name.replace(',', '')] = aff\n",
    "\n",
    "# Helper: extract country from affiliation\n",
    "def extract_country(aff):\n",
    "    if not isinstance(aff, str):\n",
    "        return None\n",
    "    country_match = re.findall(r',\\s*([A-Z][a-z]+(?:\\s[A-Z][a-z]+)*)$', aff.strip())\n",
    "    if country_match:\n",
    "        return country_match[-1]\n",
    "    return None"
   ],
   "id": "4890edeec597e0ed",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T01:58:55.519509Z",
     "start_time": "2025-11-11T01:58:55.206368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- 3. Build graph ----------\n",
    "G = nx.Graph()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    authors = [a.strip() for a in str(row['Authors']).split(',') if a.strip()]\n",
    "    title = row['Title']\n",
    "\n",
    "    for author in authors:\n",
    "        aff_text = None\n",
    "        for key in affiliation_map.keys():\n",
    "            if author.split()[0] in key:\n",
    "                aff_text = affiliation_map[key]\n",
    "                break\n",
    "        country = extract_country(aff_text) or \"Unknown\"\n",
    "\n",
    "        if not G.has_node(author):\n",
    "            G.add_node(author, affiliation=aff_text, country=country, papers=set())\n",
    "        G.nodes[author]['papers'].add(title)\n",
    "\n",
    "    # add co-author edges\n",
    "    for i in range(len(authors)):\n",
    "        for j in range(i + 1, len(authors)):\n",
    "            if G.has_edge(authors[i], authors[j]):\n",
    "                G[authors[i]][authors[j]]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(authors[i], authors[j], weight=1)"
   ],
   "id": "2b7a0a9217f4c85f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T01:59:01.111632Z",
     "start_time": "2025-11-11T01:59:01.100143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- 4. Top-10 countries ----------\n",
    "countries = [G.nodes[n]['country'] for n in G.nodes if G.nodes[n]['country'] != \"Unknown\"]\n",
    "top10 = set([c for c, _ in Counter(countries).most_common(10)])"
   ],
   "id": "5dc3710ab7581f5b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T01:59:15.617936Z",
     "start_time": "2025-11-11T01:59:15.557291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- 5. Build JSON structure ----------\n",
    "nodes = []\n",
    "for n, data in G.nodes(data=True):\n",
    "    nodes.append({\n",
    "        \"id\": n,\n",
    "        \"country\": data.get(\"country\", \"Unknown\"),\n",
    "        \"affiliation\": data.get(\"affiliation\", \"\"),\n",
    "        \"papers\": list(data.get(\"papers\", [])),\n",
    "        \"degree\": int(G.degree(n)),\n",
    "        \"isTopCountry\": data.get(\"country\") in top10\n",
    "    })\n",
    "\n",
    "links = []\n",
    "for u, v, d in G.edges(data=True):\n",
    "    links.append({\n",
    "        \"source\": u,\n",
    "        \"target\": v,\n",
    "        \"weight\": d.get(\"weight\", 1)\n",
    "    })\n",
    "\n",
    "graph_json = {\"nodes\": nodes, \"links\": links}\n",
    "\n",
    "# ---------- 6. Write to JSON file ----------\n",
    "with open(\"data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(graph_json, f, indent=2, ensure_ascii=False)"
   ],
   "id": "3bf0d3f5ed604f13",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c2a590c3afe28867"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
